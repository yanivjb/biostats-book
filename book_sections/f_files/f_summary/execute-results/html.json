{
  "hash": "d079043dca1a7fcc5177e325ea8087b6",
  "result": {
    "engine": "knitr",
    "markdown": "## â€¢ 18. F (ANOVA) summary {.unnumbered #f_summary}\n\n\n---\nformat: html\nwebr:\n  packages: ['dplyr', 'readr', 'broom' ,'ggplot2', 'forcats']\n  autoload-packages: true\n---\n\n\nLinks to: [Summary](#f_summary_chapter-summary). [Chatbot tutor](#f_summary_chatbot_tutor).  [Questions](#f_summary_practice-questions). [Glossary](#t_summary_glossary-of-terms). [R packages](#f_summaryR_packages_introduced). [R functions](#f_summary_key-r-functions). [More resources](#f_summary_additional-resources).\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Chapter summary  {#f_summary_chapter-summary}  \n \n \n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![Enjoy this \"insomnia meme\" about the ANOVA. From [this video](https://www.youtube.com/watch?v=9W4gOJZfKhA)](../../figs/linear_models/f/anova_joke.jpg){fig-alt='A four-panel comic shows a brain talking to a person in bed at night. In panel one, the brain asks, \"What is ANOVA?\" In panel two, the person replies, \"Analysis of Variance.\" In panel three, the brain nervously asks, \"Then why do we compare means?\" In panel four, the person lies awake in the dark, wide-eyed, clearly disturbed by the question. please' width=240}\n:::\n:::\n\n \nThe analysis of variance (ANOVA) provides a way to understand variation by breaking the variability attributable to our model, and variability uncounted for by our model. The F statistic compares these two sources of variation. Under the null hypothesis that the groups come from the same (statistical) population, the ratio of between to within group variation has an expected value of  one. In the special case of two groups, ANOVA and the two-sample t-test are mathematically equivalentâ€”both quantify how much separation exists between group means relative to expected sampling variation. \n\n### Chatbot tutor  {#f_summary_chatbot_tutor} \n\n:::tutor\n\n\n\nPlease interact with this custom chatbot ([**link here**](https://chatgpt.com/g/g-68db186815108191a327731289b4d1e4-f-tutor)). I have made to help you with this chapter. I suggest interacting with at least ten back-and-forths to ramp up  and then stopping when you feel like you got what you needed from it. \n\n:::\n\n\n\n\n## Practice Questions {#t_summary_practice-questions}\n\n\nTry these questions! By using the R environment you can work without leaving this \"book\". I even pre-loaded all the packages you need! \n\n\n### Part 1: Reflecting on this chapter \n\n*In this chapter we used the ANOVA to test the null hypothesis that pink and white parviflora flowers have the same admixture proportion at Sawmill Road.*  \n\n:::exercises\n\n\n\n**Q1)** Under the null hypothesis that both groups come from the same population, the expected value of $F$ is <select class='webex-select'><option value='blank'></option><option value=''>0</option><option value='answer'>1</option><option value=''>It depends on the degrees of freedom</option></select>.\n\n**Q2)** If $F$ is greater than the expected value under the null, *(select all correct)* <div class='webex-radiogroup' id='radio_HDVYRYAHGR'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HDVYRYAHGR\" value=\"\"></input> <span>The null is false</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HDVYRYAHGR\" value=\"\"></input> <span>The null is true</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HDVYRYAHGR\" value=\"\"></input> <span>We reject the null</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HDVYRYAHGR\" value=\"\"></input> <span>We fail to reject the null</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HDVYRYAHGR\" value=\"answer\"></input> <span>We may or may not reject the null depending on the degrees of freedom.</span></label></div>\n.\n\n\n**Q3)** If $F$ is less than the expected value under the null, *(select all correct)* <div class='webex-radiogroup' id='radio_DQQHNXXEIO'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DQQHNXXEIO\" value=\"\"></input> <span>The null is false</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DQQHNXXEIO\" value=\"\"></input> <span>The null is true</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DQQHNXXEIO\" value=\"\"></input> <span>We reject the null</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DQQHNXXEIO\" value=\"answer\"></input> <span>We fail to reject the null</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DQQHNXXEIO\" value=\"\"></input> <span>We may or may not reject the null depending on the degrees of freedom.</span></label></div>\n.\n\n\n**Q4)** Our p-value was very small (much less than the traditional (\\alpha = 0.05) threshold). This means... *(select all correct)*: <div class='webex-radiogroup' id='radio_FNZMRLLCGS'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FNZMRLLCGS\" value=\"answer\"></input> <span>It would be incredibly unlikely to observe such an extreme F statistic if the null hypothesis were true</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FNZMRLLCGS\" value=\"\"></input> <span>Pollinators avoid white flowers</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FNZMRLLCGS\" value=\"\"></input> <span>The pink petal color has introgressed from xantiana</span></label></div>\n. \n\n\n:::\n\n\n\n### Part 2: Recognizing types of sums of squares (from code)\n\nConsider the code below for the next three questions: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nSS <- data |>\n  mutate(grand_mean = mean(response))|>\n  group_by(explanatory)|>\n  mutate(yhat = mean(response))|>\n  ungroup()|>\n  summarise(SS_A = sum((yhat - grand_mean)^2),\n            SS_B = sum((response - yhat)^2),\n            SS_C = sum((response - grand_mean)^2) )\n```\n:::\n\n\n\n\n:::exercises\n\n**Q5)** Consider the code above. Which calculates $\\text{SS}_\\text{error}$? <select class='webex-select'><option value='blank'></option><option value=''>SS_A</option><option value='answer'>SS_B</option><option value=''>SS_C</option></select>\n\n**Q6)** Consider the code above. Which calculates $\\text{SS}_\\text{model}$? <select class='webex-select'><option value='blank'></option><option value='answer'>SS_A</option><option value=''>SS_B</option><option value=''>SS_C</option></select>\n\n**Q7)** Consider the code above. Which calculates $\\text{SS}_\\text{total}$?  <select class='webex-select'><option value='blank'></option><option value=''>SS_A</option><option value=''>SS_B</option><option value='answer'>SS_C</option></select>\n\n:::\n\n### Part 3: New analysis \n\n*Now let's look at the same question in a different location, Site 22. First let me process the data for you:*  \n\n\n\n```{webr-r}\n#| context: setup\n#| message: false\n#| warning: false\nlibrary(janitor)\nlibrary(forcats)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(broom)\nhz_link <- \"https://raw.githubusercontent.com/ybrandvain/datasets/refs/heads/master/zones_df_admix_weight_cutoff0.9_gps_dist2het_phenos_excl_GC.csv\"\n\nclarkia_s22_hz <- read_csv(hz_link)|> \n  rename(admix_proportion = `cutoff0.9`) |>\n  filter(!is.na(admix_proportion), !is.na(petal_color), subsp==\"P\", site == \"S22\")|>\n  clean_names() |>\n  mutate(tmp = as.numeric(factor(petal_color)) + admix_proportion,\n         id = factor(id),\n         id = fct_reorder(id, tmp))|>\n  select(admix_proportion, petal_color,id)\n```\n\n---\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Processing data for S22 hybrid zone\"}\nhz_link <- \"https://raw.githubusercontent.com/ybrandvain/datasets/refs/heads/master/zones_df_admix_weight_cutoff0.9_gps_dist2het_phenos_excl_GC.csv\"\n\n\nclarkia_s22_hz <- read_csv(hz_link)|> \n  rename(admix_proportion = `cutoff0.9`) |>\n  filter(!is.na(admix_proportion), !is.na(petal_color), subsp==\"P\", site == \"S22\")|>\n  clean_names() |>\n  mutate(tmp = as.numeric(factor(petal_color)) + admix_proportion,\n         id = as.factor(id),\n         id = fct_reorder(id, tmp))|>\n  select(admix_proportion, petal_color,id)\n```\n:::\n\n\n```{webr-r}\n#| autorun: true\nglimpse(clarkia_s22_hz)\n\n## CODE HERE TO FIND GROUP MEANS\n\n```\n\n---\n\n:::exercises\n**Q8)** Use the area above to find the difference in the admixture proportion between pink- and white- flowered *parviflora* plants at Site 22. Please return a positive number (pink minus white) <input class='webex-solveme nospaces' data-tol='0.002' size='6' data-answer='[\"0.0199\",\".0199\"]'/>.\n\n\n<div class='webex-solution'><button>Code</button>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  Group the dataset by petal color, then calculate the mean admixture proportion for each group\nmean_admix_by_petal_color <- clarkia_s22_hz |> \n  group_by(petal_color) |>                     # group data into pink vs white flowers\n  summarise(mean_admix = mean(admix_proportion))  # calculate mean admixture proportion per group\n\n\nmean_admix_by_petal_color #  View the resulting summary table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  petal_color mean_admix\n  <chr>            <dbl>\n1 pink            0.0330\n2 white           0.0132\n```\n\n\n:::\n\n```{.r .cell-code}\n#  Calculate the difference in mean admixture proportion between the two petal colors\n# `diff()` takes the second value minus the first value of `mean_admix`\n# (Order depends on how petal_color is sorted in the data!)\nmean_admix_by_petal_color |> \n  summarise(diff_admix = diff(mean_admix))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 1\n  diff_admix\n       <dbl>\n1    -0.0199\n```\n\n\n:::\n:::\n\n\nThis is white minus pink, so be sure to enter the absolute value.\n\n</div>\n\n\n:::\n\n\n\n::: {.cell .column-page-right}\n::: {.cell-output-display}\n![Partitioning the contribution of petal color and error to admixture proportion of pink and white parviflora plants in the S22 hybrid zone.](f_summary_files/figure-html/fig-devs2-1.png){#fig-devs2 fig-alt='Three dot-and-line plots (Aâ€“C) show admixture proportions for pink and white flowers, ordered by value. **Panel A**: Vertical lines extend from each point to its groupâ€™s mean, forming two stepped shapes. **Panel B:** Vertical lines extend from each point to a single horizontal line that spans both groups. **Panel C**: Vertical lines extend from each groupâ€™s mean to a single horizontal line across groups.' width=1152}\n:::\n:::\n\n\n\n\n:::exercises\n\n**Q9)** Consider the plots above. Which has lines showing the \"error\" deviation? <select class='webex-select'><option value='blank'></option><option value='answer'>A</option><option value=''>B</option><option value=''>C</option></select>\n\n**Q10)** Consider the plots above. Which has lines showing the \"model\" deviation? <select class='webex-select'><option value='blank'></option><option value=''>A</option><option value=''>B</option><option value='answer'>C</option></select>\n\n**Q11)** Consider the plots above. Which has lines showing the \"total\" deviation? <select class='webex-select'><option value='blank'></option><option value=''>A</option><option value='answer'>B</option><option value=''>C</option></select>\n:::\n\n---\n\nNow let's run the model! \n\n```{webr-r}\n#| autorun: true\nlm(admix_proportion ~ petal_color, data = clarkia_s22_hz)|>\n  anova()\n```\n\n:::exercises\n**Q12)** Given the p-value, what do you do to the null hypothesis? <div class='webex-radiogroup' id='radio_VCUBHYPIAJ'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VCUBHYPIAJ\" value=\"answer\"></input> <span>Reject it</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VCUBHYPIAJ\" value=\"\"></input> <span>Fail to reject it</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VCUBHYPIAJ\" value=\"\"></input> <span>Accept it</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VCUBHYPIAJ\" value=\"\"></input> <span>Fail to accept it</span></label></div>\n\n\n**Q13)** This means the null  <div class='webex-radiogroup' id='radio_UQCLCWYELS'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UQCLCWYELS\" value=\"\"></input> <span>Is true</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UQCLCWYELS\" value=\"\"></input> <span>Is false</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UQCLCWYELS\" value=\"\"></input> <span>Has a 0.00805 chance of being true</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UQCLCWYELS\" value=\"answer\"></input> <span>We canâ€™t say for sure.</span></label></div>\n\n\n**Q14)** From this output, the $R^2$ value is:   <input class='webex-solveme nospaces' data-tol='0.018' size='5' data-answer='[\"0.233\",\".233\"]'/>. \n\n\n<div class='webex-solution'><button>Help</button>\n\n \nRecall:   \n \n- $R^2 = \\frac{\\text{SS}_\\text{model}}{\\text{SS}_\\text{total}}$     \n- $\\text{SS}_\\text{total} = \\text{SS}_\\text{model} +\\text{SS}_\\text{error}$       \n\n\n</div>\n\n\n**Q15)**  From this output and your answer to question eight (\"What's the difference in mean admixture proportion by petal color\"), Cohen's D is <div class='webex-radiogroup' id='radio_QPJZVTYHMF'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QPJZVTYHMF\" value=\"\"></input> <span>Not worth reporting (< 0.01)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QPJZVTYHMF\" value=\"\"></input> <span>Tiny (0.01 â€“ 0.20)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QPJZVTYHMF\" value=\"\"></input> <span>Small (0.20 â€“ 0.50)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QPJZVTYHMF\" value=\"\"></input> <span>Medium (0.50 â€“ 0.80)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QPJZVTYHMF\" value=\"answer\"></input> <span>Large (0.80 â€“ 1.20)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QPJZVTYHMF\" value=\"\"></input> <span>Very large (1.20 â€“ 2.00)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QPJZVTYHMF\" value=\"\"></input> <span>Huge (> 2.00)</span></label></div>\n. \n\n\n<div class='webex-solution'><button>Equation for Cohen's D</button>\n\n\n$$\\text{Cohen's D} = \\frac{\\text{Difference in group means}}{\\text{pooled standard deviation}}$$\n\n</div>\n\n\n\n<div class='webex-solution'><button>Finding the pooled standard deviation</button>\n\n\nWith just two samples the mean squared error equals the pooled variance. So the square root of this is the pooled standard deviation. \n\n\n</div>\n\n\n\n\n<div class='webex-solution'><button>Math</button>\n\n\n$$D = \\frac{0.0199}{\\sqrt{0.00031557}}$$   \n\n$$D = \\frac{0.0199}{0.01776}$$     \n\n$$D = 1.12$$     \n\n</div>\n\n\n:::\n\nhttps://bookdown.org/steve_midway/DAR/understanding-anova-in-r.html\n\nhttps://www.crumplab.com/rstatsforpsych/semester-project-2021.html\n\n\n## ðŸ“Š Glossary of Terms {#f_glossary}\n\n---\n\n:::glossary\n\n\n#### ðŸ“š **1. Core Concepts**\n\n* **Analysis of Variance (ANOVA)**: A statistical framework that partitions total variability in a dataset into variability explained by a model (between groups) and variability left unexplained (within groups).\n* **Partitioning Variance**: Decomposing total variability into distinct components (e.g., model vs. error) to understand sources of variation.\n* **Null Hypothesis ($H_0$)**: The assumption that all groups are samples from the same statistical population; under Hâ‚€, the expected value of the F statistic is 1.\n* **Alternative Hypothesis ($H_1$)**: The assumption that at least one group comes from a different population, resulting in more between-group variation than expected by chance.\n\n---\n\n#### ðŸ”¢ **2. Variance Components**\n\n* **Between-Group Variability**: Variation among group means, attributed to the model (e.g., differences between pink vs. white flowers in admixture proportion).\n* **Within-Group Variability**: Variation among individuals within groups, reflecting background noise and sampling error. \n* **Total Variability**: The sum of between-group and within-group variability.\n\n---\n\n#### ðŸ§® **3. Sums of Squares, Mean Squares, and their ratio ($F$)**\n\n* **Sum of Squares (SS)**: A measure of variability; calculated by summing squared deviations.\n\n\n  * **$\\text{SS}_\\text{model}$ (aka $\\text{SS}_\\text{groups}$))**: Variability explained by our explanatory variable(s).  \n  * **$\\text{SS}_\\text{error}$ (aka $\\text{SS}_\\text{residual}$))**: Variability within groups, not explained by the model.\n  * **$\\text{SS}_\\text{total}$**: Total variability in the response variable.\n* **Degrees of Freedom (df)**: The number of independent pieces of information used to estimate variability.   \n  - $\\text{df}_\\text{model} = $n_\\text{groups}-1$.  \n  - $\\text{df}_\\text{error} = $n - n_\\text{groups}$.  \n* **Mean Square (MS)**: An estimate of variance obtained by dividing SS by its degrees of freedom.\n\n  * **$\\text{MS}_\\text{model}$** =$\\frac{\\text{MS}_\\text{model}}{\\text{df}_\\text{model}}$  \n  * **$\\text{MS}_\\text{error}$** =$\\frac{\\text{SS}_\\text{error}}{\\text{df}_\\text{error}}$ \n  \n* **F Statistic**: A ratio of variances that compares between-group variability ($\\text{MS}_\\text{model}$) to within-group variability ($\\text{MS}_\\text{error}$).\n$$F = \\frac{\\text{MS}_\\text{model}}{\\text{MS}_\\text{error}}$$  \n\n\n\n\n:::\n\n## R Packages Introduced  {#f_summaryR_packages-introduced}  \n\n:::packages\n\n\nThis chapter relies on packages you've already encountered, including:\n\n\n- **[`broom`](https://broom.tidymodels.org/)**: Tidies model outputs (like fitted values and residuals) into neat data frames.\n- **[`ggplot2`](https://ggplot2.tidyverse.org/)**: Used for visualizing data and model fits.\n\n:::\n\n\n\n## ðŸ› ï¸ Key R Functions {#f_summary_key-r-functions}\n\n:::functions\n\n* **`aov()`**:\n  Fits an analysis of variance model directly.\n\n\n* **summary()**:   Use `summary()` on the resulting object to view the ANOVA table, including sums of squares, mean squares, F statistic, and p-value.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov(response ~ group, data = dataset)|>\n  summary()\n```\n:::\n\n\n---\n\n* **`anova()`**:\n  Produces an ANOVA table from a fitted linear model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(response ~ group, data = dataset) |> \n    anova()\n```\n:::\n\n\n  This approach is mathematically identical to `aov()` for one-way ANOVA, but uses a linear model object as input.\n\n---\n\n* **`lm()`**:\n  Fits a linear model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(response ~ group, data = dataset)\n```\n:::\n\n\nOne-way ANOVA is just a special case of a linear model with a categorical predictor. This makes it easy to extend to more complex designs later.\n\n---\n\n* **`tidy()`** and **`glance()`** *(from the `broom` package)*:\n\n  * `tidy()` formats the ANOVA table into a tidy data frame.\n  * `glance()` returns model-level summaries, including ( R^2 ).\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov(response ~ group, data = dataset) |> \n  broom::glance()\n```\n:::\n\n\n::: \n\n---\n\n\n## Additional resources   {#t_summary_additional-resources}\n\n:::learnmore \n\n**Book chapters:**   \n\n[Chapter 7: Understanding the ANOVA in R](https://bookdown.org/steve_midway/DAR/understanding-anova-in-r.html) from \"[Data Analysis in R](https://bookdown.org/steve_midway/DAR/)\"\n \n**Videos:**         \n\n\n\n[Kahn Academy ANOVA](https://www.khanacademy.org/math/statistics-probability/analysis-of-variance-anova-library/analysis-of-variance-anova/v/anova-1-calculating-sst-total-sum-of-squares) \n\n[Partitioning Variance For ANOVA and linear modelling](https://www.youtube.com/watch?v=qh66ScABeM0)\n\n:::\n\n",
    "supporting": [
      "f_summary_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}