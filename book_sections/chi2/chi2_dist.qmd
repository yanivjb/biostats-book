## â€¢ 14B. $\chi^2$ distribution {.unnumbered #chi2_dist}



```{r}
#| echo: false
#| message: false
#| warning: false
library(knitr)
library(dplyr)
library(readr)
library(stringr)
library(DT)
library(webexercises)
library(ggplot2)
library(tidyr)
library(cowplot)
library(knitr)
library(dplyr)
library(readr)
library(stringr)
library(shinylive)
library(tidyr)
source("../../_common.R") 

ril_link <- "https://raw.githubusercontent.com/ybrandvain/datasets/refs/heads/master/clarkia_rils.csv"
ril_data <- readr::read_csv(ril_link) |>
  dplyr::mutate(growth_rate = case_when(growth_rate =="1.8O" ~ "1.80",
                                          .default = growth_rate),  
                growth_rate = as.numeric(growth_rate),
                visited = mean_visits > 0)
sr_rils <- ril_data |>
  filter(location == "SR", !is.na(prop_hybrid), ! is.na(mean_visits))
```


::: {.motivation style="background-color: #ffe6f7; padding: 10px; border: 1px solid #ddd; border-radius: 5px;"}

**Motivating scenario:**  I dont wanna permute! 

**Learning goals:** By the end of this chapter you should be able to:   

- Use pchisq() to find p-values for observed Ï‡Â² statistics with appropriate degrees of freedom.

-  Use `chisq.test()` to run chi-square goodness-of-fit and contingency  tests in R.

- **Understand the mathematical $\chi^2$ distribution relates to a permutation based approach, and when you can (or cannot) use this distribution for a $|chi^2$ test.

:::

---


There are two reasons why I chose to add this chapter on the $\chi^2$ tests:

1. The $\chi^2$ statistic is a common tool across the biological sciences, so students are naturally curious about what it means, how to calculate it, and how to interpret it.
2. The $\chi^2$ test has a mathematically derived sampling distribution. This means we can use that distributionâ€”rather than relying on permutationâ€”to test the null hypothesis. This idea is important because the next part of this book relies on analytical tools for null hypothesis significance testing (NHST) and for estimating uncertainty.

Here, I (reassuringly) show that  our permutation-based and analytical approaches to NHST for the $\chi^2$ lead to the same conclusions.

---

## The $\chi^2$ "Goodness of fit" test   

```{r}
#| echo: false
#| eval: false
n_bins      <- 10
sample_size <- 41
n_samples   <- 100000
expected    <- sample_size / n_bins  # 4.1

# --------------------------
# Simulate many random samples (size = 41) from 1:10
# --------------------------
sim <- tibble(
    sample_id = rep(1:n_samples, each = sample_size),
    draw      = sample(1:n_bins, size = n_samples * sample_size, replace = TRUE)
)

# Count per bin, per sample; ensure all bins exist
counts <- sim |>
    count(sample_id, draw, name = "count") |>
    complete(sample_id, draw = 1:n_bins, fill = list(count = 0)) |>
    ungroup()

# Ï‡Â² for each sample_id
chi2_per_sample <- counts |>
    group_by(sample_id) |>
    summarise(chi2 = sum((count - expected)^2 / expected), .groups = "drop")

write_csv(chi2_per_sample , "../../data/chi2_for_sim.csv")
```

```{r}
#| echo: false
#| message: false
#| warning: false
x<- tibble("chosen" = c("expected","observed"),
`1`=c(4.1,1),`2`=c(4.1,4),`3`=c(4.1,6),`4`=c(4.1,3),`5`=c(4.1,3),`6`=c(4.1,8),`7`=c(4.1,7),`8`=c(4.1,3),`9`=c(4.1,3),`10`=c(4.1,3))
kable(x)
```

---

We previously evaluated the null hypothesis that students choose an integer between one and ten at random. To do so, we:





```{r}
#| echo: false
#| column: margin
#| message: false
#| warning: false
#| label: fig-gofsim
#| fig-cap: "Simulation-derived null distribution of Ï‡Â² distribution for our example. The red vertical line shows the observed Ï‡Â² = 10.46, which falls well within the main body of the simulated distribution. Roughly 29% of simulated Ï‡Â² values were as large or larger than this observed value, yielding a one-tailed p-value â‰ˆ 0.29."
#| ig-alt: "A histogram showing the null distribution of Ï‡Â² statistics based on 100,000 simulated random draws of 41 choices between 1 and 10. The x-axis represents Ï‡Â² values (ranging from 0 to about 45), and the y-axis shows the proportion of simulations at each value. A thick red vertical line near Ï‡Â² = 10 marks the observed statistic, labeled \"observed Ï‡Â²,\" lying well within the center of the simulated distribution."
chi2_per_sample<- read_csv( "../../data/chi2_for_sim.csv")
ggplot(chi2_per_sample, aes(x = chi2))+ 
geom_histogram(color = "black", bins = 25, aes(y = ..density..), fill = "azure1")+
geom_vline(xintercept = 10.46,color = "firebrick",linewidth =2)  + 
annotate(x = 24,y =0.10,color = "firebrick", geom = "label",   
        label = "observed~chi^2",  parse = TRUE, size = 10)+
theme(axis.text = element_text(size = 22), axis.title = element_text(size = 24),title = element_text(size =17))+
labs(x = expression(chi^2), y ="proportion of simulations", title = "Simulation-derived null distribution." )#+
#  stat_function(fun = dchisq, args = list(df = 9), color = "cornflowerblue", linewidth #=2.5) 


```

1. **Calculated the expected counts:** the number of students we would expect to choose each number if choices were truly random. Since we had 41 observations for 10 categories with a null of "each is equally likely", our expectation was 4.1 for each category (above).

2. **Computed the $\chi^2$ statistic** as the sum of squared differences between observed and expected counts, divided by the expected count.  In this case this equalled 10.46.

3. **Simulated the null distribution** by repeatedly generating random choices and calculating the resulting $\chi^2$ values (@fig-gofsim)

4. **Compared our observed $\chi^2$** to this simulated null distribution to obtain a p-value and conduct a null hypothesis significance test (NHST). Approximately 29.4%  of our null simulation-based $\chi^2$ values were greater than or equal to our observed value of 10.46. Because the $\chi^2$ encompasses all types of deviations from null expectations, this is one-tailed test. Our p-value is 0.294, and we fail to reject the null hypothesis.

```{r}
library(dplyr)
chi2_per_sample |>
  mutate(as_or_more_extreme = chi2 >= 10.462)|>
  summarise(p.val = mean(as_or_more_extreme))
```


### No need to simulate!  

The null distribution of the $\chi^2$ test-statistic is known! This means we already have a null sampling distribution, so we could have skipped simulation. To use this null you simply need to know the "degrees of freedom" -- the number of values you must know before you can guess the rest.  The degrees of freedom for a goodness of fit test is the number of categories minus one. Once we have that number (in this case, 9) we can use the `pchisq()` in R to find the p value (**Make sure to only consider the upper tail of the $\chi^2$ distribution**).

:::aside
**Degrees of freedom for a $\chi^2$ "goodness of fit" test** equals the number of categories minus one.
:::


```{r}
pchisq(q = 10.462, lower.tail = FALSE, df = 9)
```

Not only are these p-values basically identical, but the sampling distributions are (more or less) the same (@fig-gofpermvchisq). 

```{r}
#| code-fold: true
#| label: fig-gofpermvchisq
#| fig-width: 12
#| fig-height: 4
#| fig-cap: "Simulated Ï‡Â² values match the  Ï‡Â² distribution. (**A**) Histogram of Ï‡Â² values from 100,000 simulated random samples (41 draws from 10 equally likely categories), overlaid with the theoretical Ï‡Â² probability density curve for 9 degrees of freedom (red line). (**B**) The relationship between Ï‡Â² values and their corresponding p-values. Each point represents a simulated Ï‡Â² statistic (black), and the red line shows the theoretical p-value function for 9 degrees of freedom."
#| fig-alt: "Two side-by-side plots labeled A and B. **Panel A** shows a histogram of simulated Ï‡Â² values (x-axis: Ï‡Â², y-axis: probability) peaking near 9, with a smooth red curve overlaid representing the theoretical Ï‡Â² distribution with 9 degrees of freedom. **Panel B shows** Ï‡Â² values on the x-axis and corresponding p-values on the y-axis, forming a steeply declining curve from 1.0 at Ï‡Â² = 0 to near 0 as Ï‡Â² increases. A red theoretical line overlaps closely with the simulated data, showing that larger Ï‡Â² values correspond to smaller p-values."

library(patchwork)


chi2_per_sample<- read_csv( "../../data/chi2_for_sim.csv")

plot_a <- ggplot(chi2_per_sample, aes(x = chi2))+
  geom_histogram(color = "black", bins = 25, aes(y = ..density..), fill = "azure1")+
  theme(axis.text = element_text(size = 16), axis.title = element_text(size = 18),
      title = element_text(size =16))+
  labs(x = expression(chi^2), y ="probability", title = expression(chi^2~~~df==9) )+
 stat_function(fun = dchisq, args = list(df = 9), color = "red", linewidth =2,alpha = .4) 




plot_b <- chi2_per_sample|>arrange(chi2)|>
    mutate(pval = rank(-chi2) / max(rank(-chi2)))|>
    ggplot(aes(x = chi2, y= pval))+ 
    labs(x = expression(chi^2), y ="p-value", title = expression(chi^2~~~df==9) )+
    geom_line(size = 1.5)+
geom_line(data = tibble(chi2 = seq(0,46,.01), pval = pchisq(chi2,9,lower.tail = FALSE)), color = "red", alpha = .3,linewidth = 3.5)+
  theme(axis.text = element_text(size = 16), axis.title = element_text(size = 18),
      title = element_text(size =16))

plot_a +plot_b+plot_annotation(tag_levels = "A")
```

### No need to calculate! 

But wait, it gets even easier. We don't even need to calculate $\chi^2$, just give it our observations and the expected proportions and R will find our $\chi^2$ value, the degrees of freedom, and the associated p-value!

:::aside
In our case, the expected proportions were all the same, so we actually didn't even need to type them. But some cases (e.g. if you're testing to see if data meet Hardy Weinberg expectations) the proportion of expected observations differs for each category.
:::


```{r}
number_data<- tibble(number = 1:10, 
                    times_picked= c(1,4,6,3,3,8,7,3,3,3),
                    expected_proportion = c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1))

chisq.test(x = pull(number_data, times_picked),
           p=  pull(number_data, expected_proportion))
```

## The $\chi^2$ "contingency" test    

```{r}
#| echo: false
library(janitor)
sr_rils  |>
    filter(!is.na(visited), !is.na(petal_color))|>
    tabyl(visited, petal_color)|>                                                                                                      kable()
```

---

We also used a simulation approach (in this case a permutation) to test the null hypothesis that two categorical variables are independent. We used the relationship between petal color and if a flower was visited from our RIL data from Sawmill Road for that example. As above, we calculated the $\chi^2$ values from expectations and simulated to generate the null distribution, which in this case, equaled 10.11. We then compared this to the null distribution (obtained by permutation) and rejected the null ($p \approx 0.0017$).

As above, we skip permutation and just compare our observed $\chi^2$ value directly to the theoretical $\chi^2$ distribution (we just need to know the degrees of freedom). A 2Ã—2 contingency table has just one degree of freedom because, once we know the overall proportions of pink flowers and of those receiving visits (needed to calculate expectations), we just need to know the value in one cell to correctly guess the rest. 

:::aside
While the $\chi^2$ example provided here considered binary outcomes, the $\chi^2$ contingency tests can be applied to categories with any number of levels. More broadly, the degrees of freedom for a $chi^2$ contingency test equals (the number  of rows - 1) $\times$ (the number  of columns - 1).
:::

So we can again use the `pchisq()` function to find the p value, being sure to set `lower.tail = FALSE`. Reassuringly, the permutation-based and analytically derived p-values align closely.

```{r}
pchisq(10.11, df = 1, lower.tail = FALSE)
```


Comparing the p-values for specific (attainable) $\chi^2$ values in this study (@fig-contingencypermvchisq), we see that the null sampling distributions for the permutation and mathematical approaches are nearly identical. 

```{r}
#| echo: false
#| eval: false
### permute the data 100k times
all_perms <- sr_rils|>
    specify(visited ~ petal_color,success = "TRUE") |>
    hypothesize(null = "independence") |>
    generate(reps = 10000, type = "permute") 

# find counts and expectations for each category
all_perms_table <-  all_perms |>
    group_by(visited, petal_color, replicate)|>    tally()|> ungroup()|>
    group_by(visited,replicate)|>    mutate(n_visited = sum(n))|>    ungroup()|>
    group_by(petal_color,replicate)|>    mutate(n_color = sum(n))|>    ungroup()|>
    group_by(replicate)|>    mutate(expect = n_color*n_visited / (sum(n)))|> mutate(expect = round(expect, digits =2))

all_perms_table_chi2 <- all_perms_table |> 
    summarise(chi2= sum((n-expect)^2/expect)) 
write_csv(all_perms_table_chi2, "../../data/chi2_for_perm.csv")

```

```{r}
#| code-fold: true
#| label: fig-contingencypermvchisq
#| fig-width: 12
#| fig-height: 4
#| fig-cap: "Comparing permutation-based p-values (black points, dashed line) to the theoretical Ï‡Â² distribution with one degree of freedom (smooth red curve). The distributions closely follow one another, but the permutation p-values decrease stepwise because there are a finite number of possible permutations, while the analytical Ï‡Â² distribution provides a smooth approximation."
#| fig-alt: "A plot showing p-values on the y-axis and Ï‡Â² values on the x-axis. Black points connected by a dashed line form a downward stepwise curve from p = 1 at Ï‡Â² = 0 to near p = 0 at Ï‡Â² â‰ˆ 10. Overlaid is a smooth red declining curve representing the theoretical Ï‡Â² distribution with one degree of freedom. The two curves align closely, illustrating that permutation-based and theoretical Ï‡Â² p-values behave similarly."


all_perms_table_chi2 <- read_csv( "../../data/chi2_for_perm.csv")


all_perms_table_chi2|>arrange(chi2)|>
    mutate(pval = rank(-chi2) / max(rank(-chi2)))|>
    ggplot(aes(x = chi2, y= pval))+ 
    labs(x = expression(chi^2), y ="p-value", title = expression(chi^2~~~df==1) )+
  geom_step(size = 1, lty =2, alpha = .5)+
    geom_point(size =4)+
geom_line(data = tibble(chi2 = seq(0,11,.01), pval = pchisq(chi2,1,lower.tail = FALSE)), color = "red", alpha = .3,linewidth = 3.5)+
  theme(axis.text = element_text(size = 16), axis.title = element_text(size = 18),
      title = element_text(size =16))


```

    
:::note
**THINK":** Both our $\chi2$ values were approximately 10. Why did we comfortably reject the null in this case and fail to reject it in the other? 

`r hide("Explanation")`
The answer is because they have different degrees of freedom!
`r unhide()`

:::

## Assumptions of the $\chi^2$ test

The $\chi^2$ test (based on its mathematical distribution) make a set of standard assumptions (i.e. random and independent sampling in each group)  shared with permutation-based tests. Additionally,  the $\chi^2$ test assumes

- All categories have an expected count greater than one, and   
- No more than 20% of categories have an expected count of less than five.  

The "sawtoothed" nature of @fig-contingencypermvchisq hints at the basis for these assumptions. Once the expected counts become small, there are only a limited number of distinct ways to rearrange observations among categories. This discreteness leads to a step-like sampling distribution, rather than the smooth curve predicted by the continuous $\chi^2$ approximation. When expected counts are too low, the approximation breaks down. Not to worry,...  you can always permute ðŸ˜‰.
