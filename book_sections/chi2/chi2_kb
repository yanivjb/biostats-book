## ğŸ“š **Knowledge Base: Ï‡Â² Tests**

### ğŸ§­ **Context**
This come after sections on null hypothesis significance testing and permutation. The students have also encountered uncertainty (standard errors and 95% CI by bootstrapping), correlation andcovariance (even as applied to categorical variable), and the ides of an effect size.

### ğŸ§­ **Section Order**

1. Motivation & Goals
2. Goodness-of-Fit Example (students picking numbers)
3. Ï‡Â² Statistic & Effect Size (Cohenâ€™s *w*)
4. Simulation-based Null Distribution (manual + `infer`)
5. Analytical Ï‡Â² Distribution
6. Contingency Table Example (flower color Ã— pollinator visits)
7. Permutation-based Null Distribution (manual + `infer`)
8. Comparing Permutation vs Ï‡Â² Distributions
9. Assumptions & Limitations
10. Chapter Summary

---

### ğŸ¯ **Overall Learning Goals**

By the end of this chapter, students should be able to:

* Explain what the Ï‡Â² statistic measures conceptually.
* Calculate Ï‡Â² statistics to summarize deviations between observed and expected counts.
* Use simulation or permutation â€” both manually and via `infer` â€” to approximate null distributions for Ï‡Â².
* Apply the `infer` pipeline to implement Ï‡Â² goodness-of-fit and contingency tests in R.
* Use the theoretical Ï‡Â² distribution to find p-values, identifying the correct degrees of freedom.
* Interpret effect size (Cohenâ€™s *w*) separately from statistical significance.
* Check assumptions and choose alternatives when Ï‡Â² approximations are invalid.

---

### ğŸ§  **Key Concepts**

* **Ï‡Â² Statistic**: A single-number summary of deviations between observed and expected counts.

* **Goodness-of-Fit Test**:
  Tests whether one categorical variable follows a specified distribution (e.g. uniform).

* **Contingency Test**:
  Tests whether two categorical variables are independent.

* **Degrees of Freedom**:

  * Goodness-of-fit: ( \text{df} = \text{# categories} - 1 )
  * Contingency: ( \text{df} = (\text{rows}-1)(\text{cols}-1) )

* **Effect Size (Cohenâ€™s w)**:
  [
  w = \sqrt{\frac{\chi^2}{n}}
  ]
  Quantifies strength of deviation, independent of sample size.

* **Null Distributions**:

  * Generated by simulation (goodness-of-fit) or permutation (contingency).
  * Or approximated by the Ï‡Â² distribution if assumptions are met.

* **Assumptions**:

  * Random, independent sampling.
  * Expected count > 1 in each category.
  * â‰¤20% of categories with expected count < 5.

---

### ğŸ§° **Using the `infer` Pipeline**

The `infer` package provides a clean and flexible workflow for Ï‡Â² tests that parallels what students learned for permutation and bootstrap earlier.

#### 1ï¸âƒ£ **Goodness-of-Fit (Simulation)**

```r
library(infer)

number_data <- tibble(
  number = 1:10,
  count = c(1,4,6,3,3,8,7,3,3,3)
)

number_data |>
  specify(response = count) |>
  hypothesize(null = "point", p = rep(0.1, 10)) |>
  generate(reps = 10000, type = "simulate") |>
  calculate(stat = "Chisq")
```

* `null = "point"` specifies expected proportions.
* `generate(type = "simulate")` samples under the null model.
* `calculate(stat = "Chisq")` uses the Ï‡Â² statistic.
* `get_p_value(obs_stat = ..., direction = "right")` retrieves the p-value.

---

#### 2ï¸âƒ£ **Contingency Test (Permutation)**

```r
sr_rils |>
  filter(!is.na(visited), !is.na(petal_color)) |>
  specify(visited ~ petal_color) |>
  hypothesize(null = "independence") |>
  generate(reps = 10000, type = "permute") |>
  calculate(stat = "Chisq", correct = FALSE) |>
  get_p_value(obs_stat = 10.1, direction = "right")
```

* `null = "independence"` breaks the relationship between variables.
* `generate(type = "permute")` shuffles explanatory labels.
* `correct = FALSE` turns off Yatesâ€™ correction for 2Ã—2 tables.
* `direction = "right"` because Ï‡Â² is one-tailed.

---

### ğŸ§ª **Worked Examples**

#### Goodness-of-fit â€” Student number picks

* Null: uniform 1â€“10.
* Observed Ï‡Â² = 10.46.
* Simulation with `infer`: p â‰ˆ 0.29.
* Theoretical Ï‡Â² (df = 9): p â‰ˆ 0.29.
* Effect size (w â‰ˆ 0.50) is large, but not statistically significant.

#### Contingency â€” Flower color Ã— pollinator visits

* Null: independence.
* Observed Ï‡Â² â‰ˆ 10.1 (df = 1).
* Permutation with `infer`: p â‰ˆ 0.002.
* Theoretical Ï‡Â²: same conclusion.
* Interpretation: pink flowers more likely to receive visits.

---

### ğŸ“Š **Key Figures**

* **Barplot (GoF)** â€” observed vs expected counts for student number picks.
* **Animated Simulation** â€” repeatedly simulating uniform draws; variability from sampling error.
* **Null Distribution (GoF)** â€” histogram of simulated Ï‡Â² values with red line for observed statistic.
* **Permutation vs Ï‡Â² (Contingency)** â€” stepwise permutation p-value curve vs smooth theoretical Ï‡Â² curve.

---

### ğŸ§‘â€ğŸ« **Tutor Guidance**

* Encourage students to describe Ï‡Â² conceptually before using formulas.
* Explicitly connect **simulation/permutation** and **analytical Ï‡Â²** as two ways of answering the same question.
* Reinforce when to use `null = "point"` vs `null = "independence"`.
* Check for understanding of **degrees of freedom** intuitively.
* Highlight how `infer` simplifies workflows and unifies different test types.
* Ask reflective questions:

  * â€œWhy do we only use the right tail for Ï‡Â²?â€
  * â€œWhy might a large effect size not be statistically significant?â€
  * â€œWhen might you prefer permutation over the Ï‡Â² distribution?â€

---

### ğŸ“ **Chapter Summary**

The Ï‡Â² test summarizes how far observed counts are from expected counts. Goodness-of-fit tests compare to a specified distribution; contingency tests check independence between variables. We can build null distributions through simulation or permutation (e.g., with `infer`), or use the analytical Ï‡Â² distribution as a shortcut when assumptions hold. Degrees of freedom determine the shape of the Ï‡Â² curve. Cohenâ€™s *w* measures effect size. When expected counts are small, permutation or exact tests are better alternatives.

